{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2v8ZgOfckN7",
        "outputId": "72b39ca0-326e-40f6-95e9-5e4deecb9a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"This is a sample text corpus. It is used for demonstrating text processing tasks such as unigrams, bigrams, trigrams, and next word prediction.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# ... (rest of your code remains the same)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2hz35LjcrEZ",
        "outputId": "b5528652-03ce-45b1-916c-37d81dfa012b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"This is a sample text corpus. It is used for demonstrating text processing tasks such as unigrams, bigrams, trigrams, and next word prediction.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# 1. Unigrams\n",
        "unigrams = list(ngrams(tokens, 1))\n",
        "unigram_counts = Counter(unigrams)\n",
        "print(\"Unigrams:\")\n",
        "print(unigram_counts)\n",
        "\n",
        "# 2. Bigrams\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_counts = Counter(bigrams)\n",
        "print(\"\\nBigrams:\")\n",
        "print(bigram_counts)\n",
        "\n",
        "# 3. Trigrams\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "trigram_counts = Counter(trigrams)\n",
        "print(\"\\nTrigrams:\")\n",
        "print(trigram_counts)\n",
        "\n",
        "# 4. Bigram probabilities\n",
        "bigram_probabilities = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_probabilities[w1][w2] += 1\n",
        "\n",
        "for w1 in bigram_probabilities:\n",
        "    total_count = float(sum(bigram_probabilities[w1].values()))\n",
        "    for w2 in bigram_probabilities[w1]:\n",
        "        bigram_probabilities[w1][w2] /= total_count\n",
        "\n",
        "print(\"\\nBigram Probabilities:\")\n",
        "for w1 in bigram_probabilities:\n",
        "    for w2 in bigram_probabilities[w1]:\n",
        "        print(f\"P({w2}|{w1}) = {bigram_probabilities[w1][w2]:.4f}\")\n",
        "\n",
        "# 5. Next word prediction\n",
        "def predict_next_word(previous_word):\n",
        "    if previous_word in bigram_probabilities:\n",
        "        next_word = max(bigram_probabilities[previous_word], key=bigram_probabilities[previous_word].get)\n",
        "        return next_word\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example of next word prediction\n",
        "previous_word = \"text\"\n",
        "predicted_word = predict_next_word(previous_word)\n",
        "print(f\"\\nNext word prediction for '{previous_word}': {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iswhRJ7icxC9",
        "outputId": "042b0f25-8fe8-42fd-f456-3ada293305a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams:\n",
            "Counter({(',',): 3, ('is',): 2, ('text',): 2, ('.',): 2, ('this',): 1, ('a',): 1, ('sample',): 1, ('corpus',): 1, ('it',): 1, ('used',): 1, ('for',): 1, ('demonstrating',): 1, ('processing',): 1, ('tasks',): 1, ('such',): 1, ('as',): 1, ('unigrams',): 1, ('bigrams',): 1, ('trigrams',): 1, ('and',): 1, ('next',): 1, ('word',): 1, ('prediction',): 1})\n",
            "\n",
            "Bigrams:\n",
            "Counter({('this', 'is'): 1, ('is', 'a'): 1, ('a', 'sample'): 1, ('sample', 'text'): 1, ('text', 'corpus'): 1, ('corpus', '.'): 1, ('.', 'it'): 1, ('it', 'is'): 1, ('is', 'used'): 1, ('used', 'for'): 1, ('for', 'demonstrating'): 1, ('demonstrating', 'text'): 1, ('text', 'processing'): 1, ('processing', 'tasks'): 1, ('tasks', 'such'): 1, ('such', 'as'): 1, ('as', 'unigrams'): 1, ('unigrams', ','): 1, (',', 'bigrams'): 1, ('bigrams', ','): 1, (',', 'trigrams'): 1, ('trigrams', ','): 1, (',', 'and'): 1, ('and', 'next'): 1, ('next', 'word'): 1, ('word', 'prediction'): 1, ('prediction', '.'): 1})\n",
            "\n",
            "Trigrams:\n",
            "Counter({('this', 'is', 'a'): 1, ('is', 'a', 'sample'): 1, ('a', 'sample', 'text'): 1, ('sample', 'text', 'corpus'): 1, ('text', 'corpus', '.'): 1, ('corpus', '.', 'it'): 1, ('.', 'it', 'is'): 1, ('it', 'is', 'used'): 1, ('is', 'used', 'for'): 1, ('used', 'for', 'demonstrating'): 1, ('for', 'demonstrating', 'text'): 1, ('demonstrating', 'text', 'processing'): 1, ('text', 'processing', 'tasks'): 1, ('processing', 'tasks', 'such'): 1, ('tasks', 'such', 'as'): 1, ('such', 'as', 'unigrams'): 1, ('as', 'unigrams', ','): 1, ('unigrams', ',', 'bigrams'): 1, (',', 'bigrams', ','): 1, ('bigrams', ',', 'trigrams'): 1, (',', 'trigrams', ','): 1, ('trigrams', ',', 'and'): 1, (',', 'and', 'next'): 1, ('and', 'next', 'word'): 1, ('next', 'word', 'prediction'): 1, ('word', 'prediction', '.'): 1})\n",
            "\n",
            "Bigram Probabilities:\n",
            "P(is|this) = 1.0000\n",
            "P(a|is) = 0.5000\n",
            "P(used|is) = 0.5000\n",
            "P(sample|a) = 1.0000\n",
            "P(text|sample) = 1.0000\n",
            "P(corpus|text) = 0.5000\n",
            "P(processing|text) = 0.5000\n",
            "P(.|corpus) = 1.0000\n",
            "P(it|.) = 1.0000\n",
            "P(is|it) = 1.0000\n",
            "P(for|used) = 1.0000\n",
            "P(demonstrating|for) = 1.0000\n",
            "P(text|demonstrating) = 1.0000\n",
            "P(tasks|processing) = 1.0000\n",
            "P(such|tasks) = 1.0000\n",
            "P(as|such) = 1.0000\n",
            "P(unigrams|as) = 1.0000\n",
            "P(,|unigrams) = 1.0000\n",
            "P(bigrams|,) = 0.3333\n",
            "P(trigrams|,) = 0.3333\n",
            "P(and|,) = 0.3333\n",
            "P(,|bigrams) = 1.0000\n",
            "P(,|trigrams) = 1.0000\n",
            "P(next|and) = 1.0000\n",
            "P(word|next) = 1.0000\n",
            "P(prediction|word) = 1.0000\n",
            "P(.|prediction) = 1.0000\n",
            "\n",
            "Next word prediction for 'text': corpus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tx02_B8Rc0Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}